{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "SOLDIERS = 5\n",
    "BATTLEFIELDS = 3\n",
    "\n",
    "def build_all_strategies():\n",
    "    # Generate combinations with replacement indices\n",
    "    combinations = itertools.combinations_with_replacement(range(BATTLEFIELDS), SOLDIERS)\n",
    "    strategies = []\n",
    "    \n",
    "    for comb in combinations:\n",
    "        strat = [0] * BATTLEFIELDS\n",
    "        for b in comb:\n",
    "            strat[b] += 1\n",
    "        strategies.append(strat)\n",
    "    \n",
    "    return strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "ALL_STRATEGIES = build_all_strategies()\n",
    "NUM_ACTIONS = len(ALL_STRATEGIES)\n",
    "\n",
    "class Player:\n",
    "    def __init__(self):\n",
    "        self.strategy = np.array([0.0] * NUM_ACTIONS)\n",
    "        self.regret_sum = np.array([0.0] * NUM_ACTIONS)\n",
    "        self.strategy_sum = np.array([0.0] * NUM_ACTIONS)\n",
    "\n",
    "    def get_strategy(self):\n",
    "        normalizing_sum = 0\n",
    "        for a in range(NUM_ACTIONS):\n",
    "            self.strategy[a] = self.regret_sum[a] if self.regret_sum[a] > 0 else 0\n",
    "            normalizing_sum += self.strategy[a]\n",
    "        for a in range(NUM_ACTIONS):\n",
    "            if normalizing_sum > 0:\n",
    "                self.strategy[a] /= normalizing_sum\n",
    "            else:\n",
    "                self.strategy[a] = 1.0 / NUM_ACTIONS\n",
    "            self.strategy_sum[a] += self.strategy[a]\n",
    "        return self.strategy\n",
    "\n",
    "    def get_action(self):\n",
    "        strategy = self.get_strategy()\n",
    "        return ALL_STRATEGIES[np.random.choice(NUM_ACTIONS, p=strategy)]\n",
    "\n",
    "    def update_regret(self, my_action, opp_action):\n",
    "        action_utility = np.array([0.0] * NUM_ACTIONS)\n",
    "\n",
    "        for strategy in ALL_STRATEGIES:\n",
    "            utility = Player.calculate_utility(strategy, opp_action)\n",
    "            action_utility[ALL_STRATEGIES.index(strategy)] = utility\n",
    "        \n",
    "        self.regret_sum += action_utility - action_utility[ALL_STRATEGIES.index(my_action)]\n",
    "    \n",
    "    def get_avg_strategy(self):\n",
    "        avg_strategy = np.array([0.0] * NUM_ACTIONS)\n",
    "        normalizing_sum = 0\n",
    "        for a in range(NUM_ACTIONS):\n",
    "            normalizing_sum += self.strategy_sum[a]\n",
    "        for a in range(NUM_ACTIONS):\n",
    "            if normalizing_sum > 0:\n",
    "                avg_strategy[a] = self.strategy_sum[a] / normalizing_sum\n",
    "            else:\n",
    "                avg_strategy[a] = 1.0 / NUM_ACTIONS\n",
    "        return avg_strategy\n",
    "    \n",
    "    @classmethod\n",
    "    def calculate_utility(cls, my_action, opp_action):\n",
    "        total_utility = 0\n",
    "        for i in range(BATTLEFIELDS):\n",
    "            if my_action[i] > opp_action[i]:\n",
    "                total_utility += 1\n",
    "            elif my_action[i] < opp_action[i]:\n",
    "                total_utility -= 1\n",
    "        return total_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500000/2500000 [05:04<00:00, 8219.31it/s]\n"
     ]
    }
   ],
   "source": [
    "me = Player()\n",
    "opp = Player()\n",
    "def train(iterations):\n",
    "    global regret_sum\n",
    "    for _ in tqdm.tqdm(range(iterations)):\n",
    "        my_action = me.get_action()\n",
    "        opp_action = opp.get_action()\n",
    "\n",
    "        me.update_regret(my_action, opp_action)\n",
    "        opp.update_regret(opp_action, my_action)\n",
    "\n",
    "\n",
    "train(2500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 0, 0]: 0.000\n",
      "[4, 1, 0]: 0.000\n",
      "[4, 0, 1]: 0.000\n",
      "[3, 2, 0]: 0.106\n",
      "[3, 1, 1]: 0.114\n",
      "[3, 0, 2]: 0.113\n",
      "[2, 3, 0]: 0.113\n",
      "[2, 2, 1]: 0.000\n",
      "[2, 1, 2]: 0.000\n",
      "[2, 0, 3]: 0.106\n",
      "[1, 4, 0]: 0.000\n",
      "[1, 3, 1]: 0.114\n",
      "[1, 2, 2]: 0.000\n",
      "[1, 1, 3]: 0.114\n",
      "[1, 0, 4]: 0.000\n",
      "[0, 5, 0]: 0.000\n",
      "[0, 4, 1]: 0.000\n",
      "[0, 3, 2]: 0.106\n",
      "[0, 2, 3]: 0.113\n",
      "[0, 1, 4]: 0.000\n",
      "[0, 0, 5]: 0.000\n",
      "[0.000 0.000 0.000 0.102 0.115 0.117 0.112 0.000 0.000 0.105 0.000 0.120\n",
      " 0.000 0.112 0.000 0.000 0.000 0.097 0.120 0.000 0.000]\n"
     ]
    }
   ],
   "source": [
    "def print_strategy(probs):\n",
    "    for prob, strat in zip(probs, ALL_STRATEGIES):\n",
    "        # round prob to 3 decimal places\n",
    "        print(f\"{strat}: {prob:.3f}\")\n",
    "\n",
    "# show avg strategy as a float, not exp notation\n",
    "with np.printoptions(precision=3, floatmode='fixed', suppress=True):\n",
    "    print_strategy(me.get_avg_strategy())\n",
    "    print(opp.get_avg_strategy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
